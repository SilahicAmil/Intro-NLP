{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Into-To-Natural-Language-Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9T4Zwe2DnMyvKLT3FJxMg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SilahicAmil/Intro-NLP/blob/main/Into_To_Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzk_KHrux01h"
      },
      "source": [
        "# Introduction to NLP fundamentals in Tensorflow\n",
        "\n",
        "NLP has the goal of deriving information of of natural language (could be, sequences, text or speech)\n",
        "\n",
        "Another common term for NLP provblems is sequence to sequence problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy0trfUU7B3b"
      },
      "source": [
        "## Check for GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfBFDLFV58qn",
        "outputId": "e9b1e9a6-d616-476a-982d-03fab5dd00cb"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-a8d759d1-3817-e0f3-8a0d-93c3849d9599)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9FguNlX6zXM"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af2YroLY6_ZB",
        "outputId": "1d26d421-8cd7-4266-fa46-0eec94af7e0d"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import a series of helper functions\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-02 04:16:43--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-07-02 04:16:43 (112 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fwmpkud7rZx"
      },
      "source": [
        "## Get our text data set\n",
        "\n",
        "The data we're going to be using is Kaggle's intro to NLP dataset (text samples of Tweets labelled as a disaster or non disaster)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZcrkFES8LLs",
        "outputId": "bb407579-69f3-4ccb-fc2e-8ae034c142e1"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "#Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-02 04:16:45--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.164.144, 172.253.115.128, 172.253.122.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.164.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2021-07-02 04:16:45 (155 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wcRAFtv8hwr"
      },
      "source": [
        "## Visualize a text dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "NI_7XglE84W_",
        "outputId": "329410f1-4135-4d1d-9bfc-30a136f7eb71"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "l8jnUXjJ9sPc",
        "outputId": "4e1be227-0841-4300-eb07-fb30159a0c4b"
      },
      "source": [
        "#Shuffle training data\n",
        "\n",
        "train_df_shuffled = train_df.sample(frac=1,\n",
        "                                    random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bdXhd3tx9zfL",
        "outputId": "54d74c57-45de-47d7-cc8a-668ebc2323b1"
      },
      "source": [
        "# What does the test data look like?\n",
        "\n",
        "test_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7HX2wvB-XYI",
        "outputId": "c6a4a70d-a59f-4d57-f7e2-0bbcdbeeb0f2"
      },
      "source": [
        "# How many examples of each class are there?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgSlqfxw-h9H",
        "outputId": "7d193757-8ed7-48a3-94ab-f4a11c5c9432"
      },
      "source": [
        "len(train_df), len(test_df)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcIXmsKu_GNc",
        "outputId": "e34f1e48-f180-4147-a17e-98947512a750"
      },
      "source": [
        "#Visualize random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # Creat random indexes\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "\n",
        "  print(f\"Target: {target}\", \"(Real Disaster)\" if target > 0 else \"(Not a real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0 (Not a real disaster)\n",
            "Text:\n",
            "There's still room for you at our party for first responders from around the country! 3rd annual best ever. http://t.co/mNh6FXhOdB\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (Not a real disaster)\n",
            "Text:\n",
            "Hellfire is surrounded by desires so be careful and donÛªt let your desires control you! #Afterlife\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (Not a real disaster)\n",
            "Text:\n",
            "ÛÏ@YMcglaun: @JulieKragt @WildWestSixGun You're a lot safer that way.Ûyeah a lot more stable &amp; if I get in trouble I have a seat right there\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (Real Disaster)\n",
            "Text:\n",
            "RT owenrbroadhurst RT JuanMThompson: At this hour 70 yrs ago one of the greatest acts of mass murder in world histÛ_ http://t.co/ODWs0waW9Q\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (Real Disaster)\n",
            "Text:\n",
            "@SourMashNumber7 @tomfromireland @rfcgeom66 @BBCTalkback They didn't succeed the other two times either. Bomb didn't detonate&amp;Shots missed.\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4H6MNj-AOC7"
      },
      "source": [
        "## Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5vgJHJ1BInR"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAAGCZBDCG8o"
      },
      "source": [
        "# Use train test split to split data into training and validation sets \n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6eDjt_VDb5x",
        "outputId": "534da026-0191-440c-ab68-bca74f6dedb9"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgfJho1NDjF8",
        "outputId": "3dfdeb8d-e970-4953-c559-69ae367cfd8e"
      },
      "source": [
        "# Check the first 10 examples\n",
        "\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wAdWY-nDtCr"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem. One of the first things youll have to do before you can build the model is to convert the text to numbers\n",
        "\n",
        "There are a few ways:\n",
        "* Tokenization - Direct mapping of token\n",
        "* Embedding- Create a matrix of feature vector for each token\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2tUDRApEMEx"
      },
      "source": [
        "## Text Vectorization (Tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifui0h0bhKfZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default Text Vectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # How many words in the vocabulary (Auto adds <OOV>)\n",
        "                                       standardize=\"lower_and_strip_punctuation\",\n",
        "                                       split=\"whitespace\",\n",
        "                                       ngrams=None, # Create groups of n_words,\n",
        "                                       output_mode=\"int\", # How to map tokens to numbers\n",
        "                                       output_sequence_length=None, # How long do you want the sequence to be\n",
        "                                       pad_to_max_tokens=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPMoQm9ijj72",
        "outputId": "4c221090-067f-4c51-f7b2-be875c268a80"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bwKwZpdkDt-"
      },
      "source": [
        "#Setup text vectorization variables\n",
        "max_vocab_length =  10000 # Max # of words to have in vocab\n",
        "max_length = 15 #Max lengeth sequence will be (average)\n",
        "\n",
        "# Update vectorizer\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIpIEqf9koYd"
      },
      "source": [
        "# fit the text vectorizer to the training text\n",
        "\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrWYpfkrBDGa",
        "outputId": "cdf7f5d3-3f2a-4fdf-d93a-25dfb3a16d7b"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGMRsuGFBRhv",
        "outputId": "794dffc1-f659-4de6-b988-c101ec27fb77"
      },
      "source": [
        "# Choose a random sentence form the training dataset and tokenize it\n",
        "\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "      \\n\\nVetorized Version:\")\n",
        "\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " #breaking Firefighters battling blaze at east Cary condo building http://t.co/mIM8hH2ce6      \n",
            "\n",
            "Vetorized Version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 379, 1083, 3161,  749,   17,  856,    1,    1,  630,    1,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAX52wh8CMgm",
        "outputId": "bf23de7f-c3e7-47a8-a295-15f9c32c0e20"
      },
      "source": [
        "# Get the unique words in the vocab\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5]\n",
        "bottom_5_words= words_in_vocab[-5:]\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 Most common words: {top_5_words}\")\n",
        "print(f\"5 Least common words: {bottom_5_words}\")\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 Most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 Least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-So6X0-dCwED"
      },
      "source": [
        "## Creating an Embedding using an Emedding Layer\n",
        "\n",
        "To make our embedding we are going to use TensorFlow's embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n30xGKXFEQfy",
        "outputId": "55f29a97-afd0-473c-a58e-7eb381ccee00"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # Input Shape\n",
        "                             output_dim=128, # Anything divisble by 8 speeds up computing with machine learning\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length=max_length)\n",
        "\n",
        "embedding"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f729381cc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4hhngYkGoNP",
        "outputId": "b5e23bb5-b649-46e9-b631-68616049e7db"
      },
      "source": [
        "# Get a random sentence from trainin set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "      n\\nEmbedded Version:\")\n",
        "\n",
        "# Embed the random sentence\n",
        "\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " Noel back up      n\n",
            "Embedded Version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.01900217, -0.00778875,  0.0252149 , ...,  0.02049587,\n",
              "         -0.03541503,  0.02888921],\n",
              "        [-0.00855951,  0.03940299, -0.04917406, ...,  0.04089766,\n",
              "         -0.04314646, -0.00851778],\n",
              "        [ 0.02618853,  0.03172157,  0.03705489, ..., -0.03908883,\n",
              "          0.02005341,  0.03536557],\n",
              "        ...,\n",
              "        [ 0.02915983, -0.00653829,  0.00810423, ..., -0.01640823,\n",
              "          0.00160346,  0.032729  ],\n",
              "        [ 0.02915983, -0.00653829,  0.00810423, ..., -0.01640823,\n",
              "          0.00160346,  0.032729  ],\n",
              "        [ 0.02915983, -0.00653829,  0.00810423, ..., -0.01640823,\n",
              "          0.00160346,  0.032729  ]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9THB3fRjHICx",
        "outputId": "4ab9a8b8-486c-4889-fd5a-f89f7a0a2138"
      },
      "source": [
        "# Check out a single tokens embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.01900217, -0.00778875,  0.0252149 ,  0.0143753 ,  0.02000191,\n",
              "        -0.02781319, -0.02472391, -0.03461609,  0.01694708,  0.04769664,\n",
              "         0.01938396, -0.03676265,  0.03805673,  0.03136755, -0.03141034,\n",
              "         0.0147112 ,  0.00924078,  0.03401972, -0.03402137, -0.0091555 ,\n",
              "         0.04875575, -0.03683907, -0.03879149, -0.03475635,  0.02311564,\n",
              "        -0.01561357,  0.00574952,  0.04904005, -0.00394764, -0.04003202,\n",
              "         0.00768739,  0.01375408, -0.03029318, -0.02753223,  0.04416238,\n",
              "         0.00457255, -0.0124725 , -0.01446985, -0.02118945, -0.03293609,\n",
              "         0.02645091, -0.01945975,  0.0086719 ,  0.02053357,  0.0203228 ,\n",
              "        -0.03013772, -0.04735538, -0.04992881,  0.03636857, -0.03751533,\n",
              "        -0.01551702, -0.02634298,  0.01285874, -0.00662382, -0.0299028 ,\n",
              "         0.02153771,  0.04789722,  0.01314703, -0.00780978, -0.03815674,\n",
              "         0.03145741, -0.04256538, -0.02866439, -0.02616819,  0.03275535,\n",
              "        -0.00554854,  0.04607533,  0.04814595, -0.04813684,  0.04215957,\n",
              "        -0.04997563,  0.00445854, -0.0157124 , -0.04962846, -0.04359914,\n",
              "        -0.03566039, -0.00887119, -0.01714676,  0.0039698 , -0.04111078,\n",
              "         0.01542981, -0.04323718, -0.04768994, -0.01886134, -0.00241427,\n",
              "         0.00380431, -0.0025077 ,  0.00213968,  0.01224066, -0.02135605,\n",
              "        -0.02681178, -0.04691739,  0.04168927,  0.01609569, -0.03584405,\n",
              "        -0.03042909,  0.02805385, -0.04672531, -0.00534524, -0.0138178 ,\n",
              "         0.03982014, -0.00305409, -0.04343047,  0.01614175,  0.00439047,\n",
              "        -0.02620506, -0.03274167,  0.02611896, -0.04397047, -0.02510886,\n",
              "         0.03794521,  0.04409189, -0.00824619,  0.03307115,  0.00510687,\n",
              "         0.02633103, -0.00887092,  0.00195607, -0.01964883,  0.00277579,\n",
              "        -0.0403083 ,  0.02747664, -0.04448397,  0.03301212, -0.02092718,\n",
              "         0.02049587, -0.03541503,  0.02888921], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'Noel back up')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhyzdOGiH3F2"
      },
      "source": [
        "## Modelling a text data set (running experiments)\n",
        "\n",
        "Now we've got a way to tunr our text sequences into numbers, it's time to start building a series of moedlling experiments.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "* Model 0: Naive bayes (baseline) - SkLearn ML Map\n",
        "* Model 1: Feed-forward nueral network (dense model)\n",
        "* Model 2: LSTM Model (RNN)\n",
        "* Model 3: GRU Model (RNN)\n",
        "* Model 4: Bidrectional-LSTM Model (RNN)\n",
        "* Model 5: 1D Covolutional Nueral Network (CNN)\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor (Transfer learning for NLP)\n",
        "* Model 8: Same as model 6 with 10% of training data\n",
        "\n",
        "How are we going to approach all 8 models?\n",
        "\n",
        "Using the standard steps in modelling is how we'll do it!\n",
        "* Create our model\n",
        "* Build a model\n",
        "* Fit a model\n",
        "* Evaluate our model\n",
        "* Experiment \n",
        "* Save and Reload the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfqw0MgmMSgR"
      },
      "source": [
        "## Model 0: Getting a basline\n",
        "\n",
        "With all machine learning model experiemnts. It's importtant to create a bseline model so you can have a benchmark for future models\n",
        "\n",
        "To create the baseline wel'll use Sklearn's Multinomial Naive Bayes using the TF-IDF formula to convert our words to number\n",
        "\n",
        "> **Note:** Common practice to use non-DL algorithms as a baseline because of their speed and then later use DL to see if you can improve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMz-4n6xl07l",
        "outputId": "ef3d8fd4-a1d3-4f27-e9d1-d5251168934d"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # Convert words to numbers\n",
        "                    (\"clf\", MultinomialNB()) # Model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "\n",
        "model_0.fit(train_sentences, train_labels)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09MBR3I1mnfs",
        "outputId": "4e806314-d6f4-4ccf-a119-328c1d770e75"
      },
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Ourbaseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ourbaseline model achieves an accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLqJ7dIbm_uf",
        "outputId": "8ca70682-baa4-4325-e985-79d672f5f2d3"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_Uc9xdCnOBO"
      },
      "source": [
        "## Create and evaluation function for the model\n",
        "\n",
        "We could evaluate with different metrics each time. That would be cumbersome and could easily be fixed with a function.\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1 Score\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQqbh1tMo9Af"
      },
      "source": [
        "# Evaluation function\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Evaluates a binary classifcation model\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  \n",
        "  # Calculate model precisions, recall and f1-score (weighted average)\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\") \n",
        "  model_results= {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1 score\": model_f1}\n",
        "  \n",
        "  return model_results"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zronHAOpq4Kg",
        "outputId": "ec621c24-d669-4164-b841-b4c2bc5b26d5"
      },
      "source": [
        "# Get baseline restults\n",
        "\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "\n",
        "baseline_results"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1 score': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvbbtMEmrKtp"
      },
      "source": [
        "## Model 1: Simple Dense Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7eMUJzubzKW"
      },
      "source": [
        "# Create a tensorboard callback (tracking model, new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save tensorboard logs\n",
        "\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE_8GZwDcQfN"
      },
      "source": [
        "# Build model with Functional API\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # One dimensional string inputs\n",
        "\n",
        "x = text_vectorizer(inputs) # Turn the input text to numbers\n",
        "\n",
        "x = embedding(x) # Embed the numberized inputs ^\n",
        "\n",
        "x = layers.GlobalAveragePooling1D()(x) # Condense feature vector for each token to a single vector\n",
        "\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Output layer. Wants binary outputs so use sigmoid\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4Vsy8BPdBP-",
        "outputId": "664f0276-dffb-4841-dab0-ce343a95b843"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GI2LBkHdGFY"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li54UBAGdiuP",
        "outputId": "ff16b014-5173-49ca-dd7e-d5dcf801f2da"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_1_dense\")])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20210702-043318\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.5580 - accuracy: 0.7884 - val_loss: 0.5176 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.3932 - accuracy: 0.8551 - val_loss: 0.4629 - val_accuracy: 0.7887\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.3130 - accuracy: 0.8813 - val_loss: 0.4523 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.2609 - accuracy: 0.9021 - val_loss: 0.4583 - val_accuracy: 0.7861\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.2212 - accuracy: 0.9209 - val_loss: 0.4699 - val_accuracy: 0.7822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptKMMDZ2eGfz",
        "outputId": "8fc2f970-e91a-4170-dc66-ec2397abbe2c"
      },
      "source": [
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4698525071144104, 0.7821522355079651]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw7CO9EBeMGr",
        "outputId": "11a5351e-f975-429b-f684-3fdec137d093"
      },
      "source": [
        "# Make some precitions and evalute \n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdnrgKcGeTR6",
        "outputId": "630b168b-a925-4409-bdf5-1c72160c9445"
      },
      "source": [
        "# First 10 predicts\n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.31518134],\n",
              "       [0.8112293 ],\n",
              "       [0.9973266 ],\n",
              "       [0.15898155],\n",
              "       [0.11760436],\n",
              "       [0.94113594],\n",
              "       [0.86556405],\n",
              "       [0.9967026 ],\n",
              "       [0.9734354 ],\n",
              "       [0.2927875 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcCyEbGvellR",
        "outputId": "4a52e6ee-b4d8-40c2-8131-b414e510eaa1"
      },
      "source": [
        "# Convert model prediction probablities ot label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "\n",
        "model_1_preds[:20]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gifhDELevKY",
        "outputId": "62273386-4da2-4c02-f8da-b6e6ee7ded0b"
      },
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.21522309711287,\n",
              " 'f1 score': 0.7799245444538409,\n",
              " 'precision': 0.7846540517195822,\n",
              " 'recall': 0.7821522309711286}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SRN3wlrgj9I",
        "outputId": "dcfc8167-2ffe-4eca-f66d-77481a6ba463"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1 score': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiQJzDo7glI_",
        "outputId": "351f35ce-99b5-4a09-f73c-3e88540e743d"
      },
      "source": [
        "# Baseline reults are outperforming the first deep learning model\n",
        "\n",
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S77HLuHVgv-X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}